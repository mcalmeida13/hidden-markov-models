{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear-regression-l2-regularization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQGKzvam9//dklqxA56dH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcalmeida13/math-machine-learning/blob/main/logistic-regression/linear_regression_l2_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y10iE2d8nnQ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daQJbWpC8vLL"
      },
      "source": [
        "N = 100\n",
        "D = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zJwI_oI8w_q"
      },
      "source": [
        "X = np.random.randn(N,D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad6q8UOC8xF7"
      },
      "source": [
        "# center the first 50 points at (-2,-2)\n",
        "X[:50,:] = X[:50,:] - 2*np.ones((50,D))\n",
        "\n",
        "# center the last 50 points at (2, 2)\n",
        "X[50:,:] = X[50:,:] + 2*np.ones((50,D))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDJfYn9Q8xK5"
      },
      "source": [
        "# labels: first 50 are 0, last 50 are 1\n",
        "T = np.array([0]*50 + [1]*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzjbnM418xPN"
      },
      "source": [
        "# add a column of ones\n",
        "# ones = np.array([[1]*N]).T\n",
        "ones = np.ones((N, 1))\n",
        "Xb = np.concatenate((ones, X), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IsZt1UQ8xUX"
      },
      "source": [
        "# randomly initialize the weights\n",
        "w = np.random.randn(D + 1)\n",
        "\n",
        "# calculate the model output\n",
        "z = Xb.dot(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8HKqpEg89gM"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ3JnT9E8_ds"
      },
      "source": [
        "Y = sigmoid(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5X-YIdF8_9E"
      },
      "source": [
        "# calculate the cross-entropy error\n",
        "def cross_entropy(T, Y):\n",
        "    E = 0\n",
        "    for i in range(len(T)):\n",
        "        if T[i] == 1:\n",
        "            E -= np.log(Y[i])\n",
        "        else:\n",
        "            E -= np.log(1 - Y[i])\n",
        "    return E\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHuU2pb09BSL",
        "outputId": "9f0207f6-59b6-4e53-9220-164858109378"
      },
      "source": [
        "# let's do gradient descent 100 times\n",
        "learning_rate = 0.1\n",
        "for i in range(100):\n",
        "    if i % 10 == 0:\n",
        "        print(cross_entropy(T, Y))\n",
        "\n",
        "    # gradient descent weight udpate with regularization\n",
        "    w += learning_rate * ( Xb.T.dot(T - Y) - 0.1*w )\n",
        "\n",
        "    # recalculate Y\n",
        "    Y = sigmoid(Xb.dot(w))\n",
        "\n",
        "\n",
        "print(\"Final w:\", w)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44793387203483986\n",
            "0.4479192695676792\n",
            "0.44790991044408635\n",
            "0.4479039140049777\n",
            "0.44790007354476324\n",
            "0.44789761494891545\n",
            "0.44789604173789116\n",
            "0.44789503558558824\n",
            "0.44789439245831514\n",
            "0.4478939816262016\n",
            "Final w: [-0.47711066  2.73817393  2.42991224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeXonH_59OYq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}